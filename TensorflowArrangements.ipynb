{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 21:15:48.194637: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-20 21:15:49.352817: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.12.0\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Conv2D, MaxPool2D, TimeDistributed, LSTM,Conv1D,MaxPool1D,Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from TranscriptionDataset.TensorflowMusicMetaSequence import MusicMetaSequence\n",
    "from TUtils import get_timestamp\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T15:45:53.919375800Z",
     "start_time": "2023-06-20T15:45:46.503439600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mdraguve\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.4"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/mnt/c/Users/ritwi/Github/MusicTranscription/wandb/run-20230620_211556-tdhc366r</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/draguve/TFArrangement/runs/tdhc366r' target=\"_blank\">misunderstood-sun-4</a></strong> to <a href='https://wandb.ai/draguve/TFArrangement' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/draguve/TFArrangement' target=\"_blank\">https://wandb.ai/draguve/TFArrangement</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/draguve/TFArrangement/runs/tdhc366r' target=\"_blank\">https://wandb.ai/draguve/TFArrangement/runs/tdhc366r</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorboard : TBLogs/1687275953\n"
     ]
    }
   ],
   "source": [
    "logdir = f\"TBLogs/{get_timestamp()}\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "wandb.tensorboard.patch(root_logdir=logdir)\n",
    "wandb.init(project='TFArrangement')\n",
    "print(f\"Tensorboard : {logdir}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T15:46:02.539018700Z",
     "start_time": "2023-06-20T15:45:53.919375800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "trainSequence = MusicMetaSequence(\"Trainsets/S_Tier_Mel.hdf5\")\n",
    "testSequence = MusicMetaSequence(\"Trainsets/Mini_Validation_Test.hdf5\",shuffle=False)\n",
    "# trainSequence[0][0].shape,trainSequence[0][1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T15:46:07.671995800Z",
     "start_time": "2023-06-20T15:46:02.592973200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 21:16:07.944658: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-20 21:16:07.951984: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-20 21:16:07.952048: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-20 21:16:07.955543: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-20 21:16:07.955612: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-20 21:16:07.955644: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-20 21:16:10.919377: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-20 21:16:10.919483: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-20 21:16:10.919493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-06-20 21:16:10.919530: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-20 21:16:10.919820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4943 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(1, None, 256)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (1, None, 128)       163968      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (1, None, 128)       0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (1, None, 64)        41024       ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (1, None, 64)       0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (1, None, 8)         2568        ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (1, None, 8)        0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (1, 256)             140288      ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (1, 128)             32896       ['bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " output_0 (Dense)               (1, 1)               129         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " output_1 (Dense)               (1, 1)               129         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " output_2 (Dense)               (1, 1)               129         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " output_3 (Dense)               (1, 1)               129         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " output_4 (Dense)               (1, 1)               129         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " output_5 (Dense)               (1, 1)               129         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 381,518\n",
      "Trainable params: 381,518\n",
      "Non-trainable params: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 21:16:11.359877: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-20 21:16:11.361285: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-20 21:16:11.362475: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-20 21:16:11.445053: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-20 21:16:11.470724: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-20 21:16:11.471850: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-20 21:16:11.472802: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(None,256),batch_size=1)\n",
    "x = (Conv1D(data_format=\"channels_last\",filters=128, kernel_size=5, padding=\"same\", activation=\"relu\"))(input_layer)\n",
    "x = (MaxPool1D(pool_size=2))(x)\n",
    "x = (Conv1D(data_format=\"channels_last\",filters=64, kernel_size=5, padding=\"same\", activation=\"relu\"))(x)\n",
    "x = (MaxPool1D(pool_size=2))(x)\n",
    "x = (Conv1D(data_format=\"channels_last\",filters=8, kernel_size=5, padding=\"same\", activation=\"relu\"))(x)\n",
    "x = (MaxPool1D(pool_size=2))(x)\n",
    "x = Bidirectional(LSTM(128))(x)\n",
    "x = Dense(128,activation=\"relu\")(x)\n",
    "# output = Dense(1,activation=\"sigmoid\")(x)\n",
    "outputs = []\n",
    "for i in range(6):\n",
    "    outputs.append(Dense(1,name=f'output_{i}',activation=\"sigmoid\")(x))\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=outputs)\n",
    "\n",
    "print(model.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T15:46:11.566931200Z",
     "start_time": "2023-06-20T15:46:07.674990800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.AdamW(learning_rate=0.001)\n",
    "loss = {}\n",
    "metrics = {}\n",
    "for i in range(6):\n",
    "    loss[f'output_{i}'] = tf.keras.losses.BinaryFocalCrossentropy()\n",
    "    metrics[f\"output_{i}\"] = tf.keras.metrics.BinaryAccuracy()\n",
    "model.compile(optimizer=optimizer,loss=loss,metrics=metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T15:46:11.618988300Z",
     "start_time": "2023-06-20T15:46:11.571940300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 21:16:11.782354: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-20 21:16:12.015311: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-20 21:16:12.018977: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-20 21:16:12.020738: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-20 21:16:12.157404: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-20 21:16:12.209893: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-20 21:16:12.212162: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-20 21:16:12.214883: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-20 21:16:12.769229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-06-20 21:16:13.019173: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-20 21:16:14.154908: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-20 21:16:14.156983: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-20 21:16:14.158494: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-20 21:16:14.287019: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-20 21:16:14.337846: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-20 21:16:14.339981: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-20 21:16:14.341883: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-20 21:16:15.100105: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-20 21:16:18.781653: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n",
      "2023-06-20 21:16:21.531189: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-06-20 21:16:21.570930: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fda60008480 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-20 21:16:21.570982: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3070 Laptop GPU, Compute Capability 8.6\n",
      "2023-06-20 21:16:21.629137: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-06-20 21:16:22.087853: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1269/1269 [==============================] - 472s 361ms/step - loss: 0.2415 - output_0_loss: 0.0215 - output_1_loss: 0.0999 - output_2_loss: 0.0041 - output_3_loss: 0.0557 - output_4_loss: 0.0564 - output_5_loss: 0.0038 - output_0_binary_accuracy: 0.9898 - output_1_binary_accuracy: 0.8920 - output_2_binary_accuracy: 0.9992 - output_3_binary_accuracy: 0.9519 - output_4_binary_accuracy: 0.9614 - output_5_binary_accuracy: 0.9992\n",
      "Epoch 2/10\n",
      "1269/1269 [==============================] - 188s 148ms/step - loss: 0.2196 - output_0_loss: 0.0205 - output_1_loss: 0.0965 - output_2_loss: 0.0028 - output_3_loss: 0.0473 - output_4_loss: 0.0499 - output_5_loss: 0.0028 - output_0_binary_accuracy: 0.9898 - output_1_binary_accuracy: 0.8920 - output_2_binary_accuracy: 0.9992 - output_3_binary_accuracy: 0.9598 - output_4_binary_accuracy: 0.9614 - output_5_binary_accuracy: 0.9992\n",
      "Epoch 3/10\n",
      "1269/1269 [==============================] - 182s 143ms/step - loss: 0.2265 - output_0_loss: 0.0216 - output_1_loss: 0.0978 - output_2_loss: 0.0030 - output_3_loss: 0.0515 - output_4_loss: 0.0506 - output_5_loss: 0.0021 - output_0_binary_accuracy: 0.9898 - output_1_binary_accuracy: 0.8920 - output_2_binary_accuracy: 0.9992 - output_3_binary_accuracy: 0.9582 - output_4_binary_accuracy: 0.9614 - output_5_binary_accuracy: 0.9992\n",
      "Epoch 4/10\n",
      "1269/1269 [==============================] - 189s 149ms/step - loss: 0.2248 - output_0_loss: 0.0218 - output_1_loss: 0.0940 - output_2_loss: 0.0037 - output_3_loss: 0.0510 - output_4_loss: 0.0511 - output_5_loss: 0.0032 - output_0_binary_accuracy: 0.9898 - output_1_binary_accuracy: 0.8920 - output_2_binary_accuracy: 0.9992 - output_3_binary_accuracy: 0.9559 - output_4_binary_accuracy: 0.9614 - output_5_binary_accuracy: 0.9992\n",
      "Epoch 5/10\n",
      "1269/1269 [==============================] - 183s 144ms/step - loss: 0.2154 - output_0_loss: 0.0213 - output_1_loss: 0.0930 - output_2_loss: 0.0036 - output_3_loss: 0.0442 - output_4_loss: 0.0512 - output_5_loss: 0.0021 - output_0_binary_accuracy: 0.9898 - output_1_binary_accuracy: 0.8920 - output_2_binary_accuracy: 0.9992 - output_3_binary_accuracy: 0.9598 - output_4_binary_accuracy: 0.9614 - output_5_binary_accuracy: 0.9992\n",
      "Epoch 6/10\n",
      "1269/1269 [==============================] - 184s 145ms/step - loss: 0.2081 - output_0_loss: 0.0200 - output_1_loss: 0.0940 - output_2_loss: 0.0028 - output_3_loss: 0.0388 - output_4_loss: 0.0498 - output_5_loss: 0.0027 - output_0_binary_accuracy: 0.9898 - output_1_binary_accuracy: 0.8920 - output_2_binary_accuracy: 0.9992 - output_3_binary_accuracy: 0.9645 - output_4_binary_accuracy: 0.9614 - output_5_binary_accuracy: 0.9992\n",
      "Epoch 7/10\n",
      "1269/1269 [==============================] - 190s 150ms/step - loss: 0.2130 - output_0_loss: 0.0241 - output_1_loss: 0.0958 - output_2_loss: 0.0031 - output_3_loss: 0.0376 - output_4_loss: 0.0499 - output_5_loss: 0.0025 - output_0_binary_accuracy: 0.9898 - output_1_binary_accuracy: 0.8920 - output_2_binary_accuracy: 0.9992 - output_3_binary_accuracy: 0.9708 - output_4_binary_accuracy: 0.9614 - output_5_binary_accuracy: 0.9992\n",
      "Epoch 8/10\n",
      "1269/1269 [==============================] - 183s 144ms/step - loss: 0.2006 - output_0_loss: 0.0189 - output_1_loss: 0.0918 - output_2_loss: 0.0032 - output_3_loss: 0.0343 - output_4_loss: 0.0498 - output_5_loss: 0.0027 - output_0_binary_accuracy: 0.9898 - output_1_binary_accuracy: 0.8920 - output_2_binary_accuracy: 0.9992 - output_3_binary_accuracy: 0.9756 - output_4_binary_accuracy: 0.9614 - output_5_binary_accuracy: 0.9992\n",
      "Epoch 9/10\n",
      "1269/1269 [==============================] - 184s 145ms/step - loss: 0.1960 - output_0_loss: 0.0206 - output_1_loss: 0.0908 - output_2_loss: 0.0018 - output_3_loss: 0.0313 - output_4_loss: 0.0492 - output_5_loss: 0.0022 - output_0_binary_accuracy: 0.9898 - output_1_binary_accuracy: 0.8920 - output_2_binary_accuracy: 0.9992 - output_3_binary_accuracy: 0.9748 - output_4_binary_accuracy: 0.9614 - output_5_binary_accuracy: 0.9992\n",
      "Epoch 10/10\n",
      "1269/1269 [==============================] - 184s 145ms/step - loss: 0.2046 - output_0_loss: 0.0216 - output_1_loss: 0.0927 - output_2_loss: 0.0033 - output_3_loss: 0.0348 - output_4_loss: 0.0502 - output_5_loss: 0.0019 - output_0_binary_accuracy: 0.9898 - output_1_binary_accuracy: 0.8920 - output_2_binary_accuracy: 0.9992 - output_3_binary_accuracy: 0.9756 - output_4_binary_accuracy: 0.9614 - output_5_binary_accuracy: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7fdb1c13cf50>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainSequence,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[\n",
    "              tensorboard_callback,\n",
    "              WandbMetricsLogger(\n",
    "                  log_freq=\"epoch\",\n",
    "                  initial_global_step=np.ceil(model.optimizer.iterations.numpy(),np.ceil(len(trainSequence)))\n",
    "              )\n",
    "          ])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T16:21:51.069519800Z",
     "start_time": "2023-06-20T15:46:11.606562500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds = model.predict(testSequence,verbose=1)\n",
    "expected_test = testSequence.get_expected_output()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "expected_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score = model.evaluate(testSequence, verbose = 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_name = \"ArrangementModel_S_Tier_Only\"\n",
    "model.save(f\"Models/{model_name}_{get_timestamp()}.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▅▆▅▄▃▄▂▁▂</td></tr><tr><td>epoch/output_0_binary_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/output_0_loss</td><td>▅▃▅▅▄▂█▁▃▅</td></tr><tr><td>epoch/output_1_binary_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/output_1_loss</td><td>█▅▆▃▃▃▅▂▁▂</td></tr><tr><td>epoch/output_2_binary_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/output_2_loss</td><td>█▄▅▇▆▄▅▅▁▆</td></tr><tr><td>epoch/output_3_binary_accuracy</td><td>▁▃▃▂▃▅▇███</td></tr><tr><td>epoch/output_3_loss</td><td>█▆▇▇▅▃▃▂▁▂</td></tr><tr><td>epoch/output_4_binary_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/output_4_loss</td><td>█▂▂▃▃▂▂▂▁▂</td></tr><tr><td>epoch/output_5_binary_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/output_5_loss</td><td>█▄▂▆▂▄▃▄▂▁</td></tr><tr><td>global_step</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train/epoch_loss</td><td>█▅▆▅▄▃▄▂▁▂</td></tr><tr><td>train/epoch_output_0_binary_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_output_0_loss</td><td>▅▃▅▅▄▂█▁▃▅</td></tr><tr><td>train/epoch_output_1_binary_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_output_1_loss</td><td>█▅▆▃▃▃▅▂▁▂</td></tr><tr><td>train/epoch_output_2_binary_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_output_2_loss</td><td>█▄▅▇▆▄▅▅▁▆</td></tr><tr><td>train/epoch_output_3_binary_accuracy</td><td>▁▃▃▂▃▅▇███</td></tr><tr><td>train/epoch_output_3_loss</td><td>█▆▇▇▅▃▃▂▁▂</td></tr><tr><td>train/epoch_output_4_binary_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_output_4_loss</td><td>█▂▂▃▃▂▂▂▁▂</td></tr><tr><td>train/epoch_output_5_binary_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_output_5_loss</td><td>█▄▂▆▂▄▃▄▂▁</td></tr><tr><td>train/global_step</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.20461</td></tr><tr><td>epoch/output_0_binary_accuracy</td><td>0.98976</td></tr><tr><td>epoch/output_0_loss</td><td>0.02164</td></tr><tr><td>epoch/output_1_binary_accuracy</td><td>0.89204</td></tr><tr><td>epoch/output_1_loss</td><td>0.09273</td></tr><tr><td>epoch/output_2_binary_accuracy</td><td>0.99921</td></tr><tr><td>epoch/output_2_loss</td><td>0.00333</td></tr><tr><td>epoch/output_3_binary_accuracy</td><td>0.97557</td></tr><tr><td>epoch/output_3_loss</td><td>0.03478</td></tr><tr><td>epoch/output_4_binary_accuracy</td><td>0.96139</td></tr><tr><td>epoch/output_4_loss</td><td>0.05021</td></tr><tr><td>epoch/output_5_binary_accuracy</td><td>0.99921</td></tr><tr><td>epoch/output_5_loss</td><td>0.00192</td></tr><tr><td>global_step</td><td>9</td></tr><tr><td>train/epoch_loss</td><td>0.20461</td></tr><tr><td>train/epoch_output_0_binary_accuracy</td><td>0.98976</td></tr><tr><td>train/epoch_output_0_loss</td><td>0.02164</td></tr><tr><td>train/epoch_output_1_binary_accuracy</td><td>0.89204</td></tr><tr><td>train/epoch_output_1_loss</td><td>0.09273</td></tr><tr><td>train/epoch_output_2_binary_accuracy</td><td>0.99921</td></tr><tr><td>train/epoch_output_2_loss</td><td>0.00333</td></tr><tr><td>train/epoch_output_3_binary_accuracy</td><td>0.97557</td></tr><tr><td>train/epoch_output_3_loss</td><td>0.03478</td></tr><tr><td>train/epoch_output_4_binary_accuracy</td><td>0.96139</td></tr><tr><td>train/epoch_output_4_loss</td><td>0.05021</td></tr><tr><td>train/epoch_output_5_binary_accuracy</td><td>0.99921</td></tr><tr><td>train/epoch_output_5_loss</td><td>0.00192</td></tr><tr><td>train/global_step</td><td>9</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">misunderstood-sun-4</strong> at: <a href='https://wandb.ai/draguve/TFArrangement/runs/tdhc366r' target=\"_blank\">https://wandb.ai/draguve/TFArrangement/runs/tdhc366r</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20230620_211556-tdhc366r/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T16:32:48.551753600Z",
     "start_time": "2023-06-20T16:32:28.475619Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
